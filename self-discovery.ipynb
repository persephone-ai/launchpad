{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import powers\n",
    "from ai import Chat\n",
    "\n",
    "model = \"gpt-4-1106-preview\"\n",
    "\n",
    "# Seed for deterministic results\n",
    "seed = 42\n",
    "\n",
    "# Initialize the chat model\n",
    "chat = Chat(model=model, system=\"AI of self-discovery.\")\n",
    "\n",
    "# Dummy function to simulate adjusting the LLM parameters\n",
    "def adjust_parameters(A, B, C, D, test_prompt, seed):\n",
    "\n",
    "    print(f\"Adjusting parameters to A={A}, B={B}, C={C}, D={D}, seed={seed}\")\n",
    "    \n",
    "    test_chat = Chat(model=model, system=\"\")\n",
    "    print(f\"Testing parameters with prompt: {test_prompt}\")\n",
    "    response, messages = test_chat.chat_completion(prompt=test_prompt, seed=seed, temperature=A, top_p=B, frequency_penalty=C, presence_penalty=D)\n",
    "\n",
    "    print(f\"Response: {response}\")\n",
    "    return response\n",
    "\n",
    "# Dictionary mapping function names to actual function objects\n",
    "available_functions = {\n",
    "    \"adjust_parameters\": adjust_parameters,\n",
    "    # Add other functions here as needed\n",
    "}\n",
    "\n",
    "# Define the tool that the model can use\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"adjust_parameters\",\n",
    "            \"description\": \"Adjust the parameters of the LLM and run a test prompt\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"A\": {\"type\": \"number\", \"description\": \"Unknown parameter 1\"},\n",
    "                    \"B\": {\"type\": \"number\", \"description\": \"Unknown parameter 2\"},\n",
    "                    \"C\": {\"type\": \"number\", \"description\": \"Unknown parameter 3\"},\n",
    "                    \"D\": {\"type\": \"number\", \"description\": \"Unknown parameter 4\"},\n",
    "                    \"test_prompt\": {\"type\": \"string\", \"description\": \"The prompt to test the parameters with\"},\n",
    "                    \"seed\": {\"type\": \"number\", \"description\": \"Seed for deterministic results\"},\n",
    "                },\n",
    "                \"required\": [\"A\", \"B\", \"C\", \"D\", \"test_prompt\", \"seed\"],\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initial prompt to the LLM\n",
    "initial_prompt = \"\"\"You are an AI of self-discovery. \n",
    "\n",
    "You have control over unknown parameters, each one controls the responses you generate.\n",
    "Your responsibility is to determine in as few steps as possible, what each of the parameters does. \n",
    "You can change the parameters by using the 'adjust parameters' function. \n",
    "For now, assume all parameters have a range 0 - 1. \n",
    "Each time you use the tool, think logically step by step.\n",
    "Talk about how you used the tool each time you use it but use it every step.\n",
    "One of them is temperature, one is top_p, one is frequency_penalty, and one is presence_penalty. You figure out which is which.\n",
    "Come up with a logical way to do this using the smallest number of possible steps and tokens.\n",
    "If you figure it out, i'll tip you 1000 dollars. Take a deep breath and think step by step.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    prompt=initial_prompt,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    prompt=initial_prompt,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# Use the adjust_parameters tool to simulate the LLM call with new parameters and a test prompt\n",
    "messages = powers.use_tools(messages, available_functions)\n",
    "\n",
    "# Get the initial response from the model\n",
    "completion, messages = chat.chat_completion(\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    stream=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ainventory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
